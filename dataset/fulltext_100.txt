A Comparison of Online and Face-to-Face Cohorts in a School Library Media Specialist Graduate Program: A Preliminary Study Shana Pribesh, Gail K. Dickinson and Katherine I Bucher School Library Media Specialist training via distance education is of interest to the library community which is seeking to stem the shortage of school li- brary personnel. However, the effectiveness of distance education compared to face-to-face delivery has not been thoroughly evaluated. This study com- pares one graduate-level School Library Media Specialist program delivered both through online and face-to-face instructional delivery methods. We found that, for the most part, the two student cohorts (distance and face-to-face) performed equally in the areas demonstrating content knowl- edge. However, the online cohort earned fewer points than the face-to-face cohort on some project activities demonstrating the difficulty in relating the intricacies of project work via an online course. This study suggests that the delivery of School Library Media Specialist training can be conducted through an online format if attention is paid to communicating the details of project based work. Challenges of Online Distance Education Beginning as correspondence courses in 1 888, distance education (DE) in the library profession has evolved though stages of traveling faculty mem- bers, televised courses, and satellite communications to Internet or online courses1 in an attempt to "reach audiences that are not well served by tradi- tional delivery methods."2 Today, "the Internet has become a regular part of the education of the next generation of library and information profession- als."3 Over the years, researchers have examined the many facets of DE4 and, more specifically, the importance of online DE in library and information science (LIS) programs.5 They have found several barriers to effective on- line DE programs including technology problems, isolation of students, limited access to library resources, pressures of personal commitments, in- flexible instructors, and unclear course requirements and instructor expec- tations.6 Researchers have focused on four major issues: effectiveness of J. of Education for Library and information Science, Vol. 47, No. 4- Fall 2006 ISSN: 0748-5786 Â©2006 Association for Library and Information Science Education 303
304 Journal of Education for Library and Information Science About the Authors Shana Pribesh (spribesh@odu.edu) is an assistant professor, and Gail K. Dickinson (GDickins@odu.edu) is an associate professor and Katherine T. Bucher (kbucher@odu.edu) is a professor in the Department of Educational Cur- riculum and Instruction, Old Dominion University, Norfolk, VA. Ms. received 05/06; accepted 01/07; revised 01/07. the programs, learner perceptions, learner attributes, and delivery technol- ogies.7 A great deal of current research on DE centers on the last three issues,8 especially on student attitudes and community-building. Developing a sense of community and fostering positive student perceptions are essen- tial elements in providing successful online educational experiences9 and a number of researchers have explored this. Combining delivery technolo- gies with community building, Nicholson explored the development of communication scaffolds through technology selection.10 The evaluation of program effectiveness, the fourth issue, presents some serious problems for researchers. Although a number of studies have shown that DE courses in general are comparable or superior to face-to-face (F2F) instruction,11 online distance education programs are often perceived by library employers and other professionals as inferior to traditional programs. 12 Contributing to this perception is the fact that many of the studies of DE were based on older televised or satellite delivery modes and not on Internet delivery. A comprehensive review of the re- search on teaching courses online "did not reveal much discussion of evalu- ation in online courses."13 The majority of the research on learning outcomes in the cognitive domain in online courses has used examinations (especially midterms and finals) as a basis for comparison.14 Mandinach maintains that effective evaluation of on-line DE must rely on the develop- ment of new forms of assessment to measure both knowledge and skills.15 "It would be difficult to create randomly assigned treatment and control groups, ensuring equivalent groups, because of the diverse and unknown characteristics of online student populations."16 Thus assessment of online DE must include rubrics, and instruction must provide detailed explana- tions of all assignments with examples of acceptable and unacceptable work.17 As Lorenzetti points out, with online DE must come a great focus on accountability. Traditional assessment tools of true-false and multiple choice tests are limited in the online environment and need to be replaced.18 Accrediting agencies such as the American Library Association (ALA), the American Association of School Librarians (AASL), and the National Council for the Accreditation of Teacher Education (NCATE) are leading the call for new assessments of student learning. Associations are changing the ways in which institutions demonstrate compliance with national pro-
A Comparison of Online and Face-to-Face Cohorts 305 fessional standards. Instead of asking programs to submit course syllabi which show all components of the standards, many associations demand proof that college students, now called candidates, demonstrate the knowl- edge, skills and dispositions listed in the standards and that the candidates who work in school libraries show that they have an impact on student learning in K-12 classrooms and libraries.19 While basic knowledge can be measured on examinations, the skills, ap- plications, and dispositions must be measured on authentic assessments of project-based learning and real-world problem-solving. Hargis defines project-based learning as "a method of teaching that engages the learner in finding solutions to important questions that are interesting to them and can be carried out through a process of investigation and collaboration."20 In this study, students were assigned projects based on a school library media center of their choice. Planning the renovation of the school library facility, preparing a budget, and writing a grant based on school and community needs engaged the students to research solutions to the unique problems of a specific school library. Project-based learning can be difficult to teach even in a F2F classroom. As Tallman and Fitzgerald pointed out, "one of the most difficult issues with online teaching has been to make the clarity of assignments such that students understand what they need to do."21 The opportunities for modify- ing, modeling or explaining assignments in F2F classes are difficult to translate to the on-line environment.22 Thus, this research project sought to examine project-based learning in a school library media program and to compare the assessment of students in a primarily face-to-face introduc- tory class with students taking the same class in a primarily on-line envi- ronment. Background of the Project Shortage of School Library Media Specialists The Commonwealth of Virginia faces a critical shortage of school library media specialists (SLMS). The Report on Supply and Demand of Instruc- tional Personnel in Virginia, 2003-2004, indicated that in 2001-2002, the percent of SLMS positions filled by unendorsed (non-licensed) personnel was 3.4%. The report noted that "[estimates of the supply . . . over the next five years provide little remedy for the current shortages."23 In a 2000 sur- vey of both SLMS and school division personnel directors, the Virginia Ed- ucational Media Association (VEMA) found that 52.9% of SLMS plan to retire before the year 2009.24 Although school library media is a critical need area, there are few op- tions for education within the Commonwealth. Virginia has no American Library Association (ALA) accredited library school. In addition, there are only two universities that have school library programs which are nation- ally recognized by the American Association of School Librarians and ac- credited by the National Council for the Accreditation of Teacher
306 Journal of Education for Library and Information Science Education. Of these two programs, Old Dominion University is in the ex- treme southeastern part of the state while Longwood University is in the south central region. When SLMS positions become vacant, school districts throughout the Commonwealth hire unlicensed individuals. Then, the districts must find ways for these individuals to gain the professional education that they need to meet the state licensure standards. Until these individuals become li- censed, the district is not in compliance with the state accreditation stan- dards for public schools. Because of the location of the two nationally recognized programs, many individuals are not able to commute to one of these programs. As a result, non-licensed SLMS in Virginia take courses wherever and whenever they can with the hope of meeting state requirements as soon as possible. Development of the Online Graduate Program In June 2005, the Institute for Museum and Library Services (IMLS) pro- vided a grant for Old Dominion University (ODU) to develop a distributed graduate program for SLMS that would be offered online with a weekend in the spring and fall semesters and a week during the summer spent on the campus in Norfolk, VA. Partnering with the University in the grant are school divisions in two of the Virginia Department of Education (VDOE) superintendents' regions; Region VII in the extreme southwest and Region IV in the north. [See Figure 1] The online SLMS program targets licensed teachers who are moving into school library media centers and provides funding to two cohorts of twenty teachers each. Students in the program have the option of obtaining the SLMS endorsement only or taking addi- tional credits for a master's degree. The partner school divisions show a wide range of racial, ethnic, reli- gious, cultural, and social diversity. For example, communities in the Figure 1 Virginia Superintendents' Regions IV (north) and VII (southwest).
A Comparison of Online and Face-to-Face Cohorts 307 mountains of Region VII are over 400 miles from the state capital of Rich- mond and face economic problems not found in the northern Region IV where high population density and urban challenges abound. There is great diversity within each of the regions as well. While statistics are not cur- rently available on the diversity of teachers within the Commonwealth, there is information on the students in each school division. According to the September 2005 report of student membership for the entire Common- wealth, the ethnic breakdown of all students in Virginia is 0.3% American Indian/Alaska native, 4.8% Asian/Pacific Islander, 26.6% Black, 7.5% Hispanic, 55.8% White, and 2.8% other/unspecified.25 Table 1 shows more specific information for representative school divisions in each of the part- ner VDOE superintendents' region. These two regions also have great eco- nomic and educational diversity as shown in Table 2.26 At the university, faculty in the library program work with ODU's Center for Learning Technologies (CLT) which provides faculty with multimedia development labs, graphics, instructional design, learning assessment, and multimedia duplication and production. The CLT Instructional Design Group provides web development for coursework that will be placed on Blackboard as a course delivery system, assists in the development of in- structional materials, and prepares course evaluations. CLT staff also en- sures that students in distance classes can submit assignments by mail or electronically. They work with ODU's Perry Library to provide access to li- brary resources and required readings as well as to the full-text databases which are available to all students. Candidates in the distributed program must meet the same admission standards including transcript and license review and follow the same pro- gram as on-campus students. In addition, they must have a recommenda- tion from their principal supporting their application. Before signing a letter of acceptance outlining the service expectations required to receive tuition funding from the grant, students in the cohort complete an online self assessment to determine whether online learning is right for them and an online technology skills and equipment self-test. Research Questions and Hypotheses This study presents preliminary findings from a larger project evaluation. Specifically, we were interested in the performance of the two cohorts, dis- tributed and face-to-face, in the introductory course for the library media specialist graduate program. We posed the following research questions: â¢ RQ1 : How does the online cohort perform compared to the face-to-face cohort on project-based activities? â¢ RQ2: How does the online cohort perform compared to the face-to-face cohort on content-based activities? We hypothesized that both the DE and F2F cohorts would perform simi- larly in terms of project- and content-based activities.
308 Journal of Education for Library and Information Science oi i- s Ã¬Â£ ss ^ afc ss 0) 5 c\j lo o Â«~ ^ Â£ a r^iri^ dÃ² oÂ£ tf) vp \P 0"^ >sp 0s- V.O >sP \O *5 tf) 6*- vp a^ \P 0"^ >sp 0s- V.O o^ >sP Ã²^ \O â¢ - r- -^r r- lo cnj r^ Â£ ufi io co lo r- a> ^ -^ LO C\J O) CD CD o .Â£ c\j ^ evi Â° Â° Z â o ^ e ^ s-S o$ ^ ^ ^ ^ <0j2 H^oqcNJoocD "o Q. "v. g5 odo d C e .5 _ .? "5.2 SS-dSqO 1 1 I i 2 S Â§ Â« Â«85 <^|^ 5 c 5 <i> ^ iff 5 <i> ^ Â¿ i J > â a > CO O f S ? -I Â« ?. Is- LU O Q _c O Â«3 CO t5 a *C LU Â¡I IÂ» h o a> JBB VÃ5 V^ VÃ^ ^sQ V^ sP Â«O cvid^r^oÃ³d Q Â£ CT> O) 00 (D LO CD O O) F 3 o o o o o o C qoqqqq â¢" C7) "^ r^ CO O) r- (D CD 00 O LO O) CD ,*Â¡ C\J O) CNJ CO CM C\J CL CO CO r-' CNJ 00 O (0 CO LO ^- CNJ r- (XJ I 5> S S i i 8 â S* Â§ .b cr 6 Â¿ a) Â§ o* g h- S Â«-1 g u_ h- Q O c c E q> Ã¡ I J > â o > oo O I ! LU Â«8 S Â£ *Â¡ CL 2 O) o â¢o 75 o 'â¦3 (0 O Ã "O (0 Ã¼ o o o LU
A Comparison of Online and Face-to-Face Cohorts 309 Methodology Sample We compared students who participated in ODU's online ECI 675 Admin- istration, Management and Evaluation of Libraries course with those who enrolled in the face-to-face section of the same course. The two groups rep- resent independent convenience samples and came to be in the instructional groups in different ways. The 19 students enrolled in the DE course were from two superintendent's regions in Virginia that are participating in a LMS graduate training program offered by ODU and sponsored by IMLS. The candidates were either nominated by their principals or indicated an in- terest in the graduate program. Apart from their geographical location, the most notable thing about this group is that ODU and IMLS will pay for their course credits if the students maintain a B- grade point average. The comparison group consisted of 14 students who attended the face-to-face ECI 675 Administration, Management and Evaluation of Li- braries course at the main campus of Old Dominion University located in Norfolk, Virginia. These students self-selected themselves into the course and training program as well as paid for their course credits. The DE and F2F cohorts were similar in demographic make up in most ways other than their geographic location. Undergraduate GPA is an important predictor of how students will perform in graduate courses. Both groups, the DE and F2F cohorts, had an average undergraduate GPA of 3.3 - the equivalent of a B average. Approximately 30% of students in each cohort had already earned a masters degree. The two groups had similar teaching experience with approximately 8 years on average. However, the online cohort was slightly younger with an average age of 35 years versus the face-to-face av- erage age of 40 years. The two cohorts were overwhelmingly female but the F2F cohort had slightly more males (14% versus the 5% in the DE cohort). The most notable difference was in ethnicity composition of the two groups. The online cohort, drawn from Northern and Southwestern Vir- Online Mean Face-to-Face Demographics (n= 1 9) Mean (n= 1 4) Undergraduate GPA 3.3 3.3 Bachelors 74% 71% Masters 26% 29% White 90% 79% Minority 10% 21% Male 5% 14% Female 95% 86% Age 35.3 years 39.5 years Years Teaching 8.3 years 7.9 years Table 3 Sample demographic characteristics.
310 Journal of Education for Library and Information Science ginia, were 90 percent white where as the face-to-face cohort, drawn from the Hampton Roads area, was only 80 percent white. Course Description The students in this study were enrolled in ECI 675: Administration, Man- agement and Evaluation of Libraries (ECI 675). This course is considered the school library program administration course with course content simi- lar to that taught in all accredited or nationally recognized school library media programs. The course goal is to prepare the prospective SLMS for the program administration role of the school library media specialist. The course is designed to assess both content knowledge - which was measured on examinations - and project-based knowledge - measured by skills, applications, and dispositions as measured on authentic real-world problem-solving. Project-based learning provides an assessment mecha- nism to not only determine if students have mastered content but to also de- termine if they can apply said content in a real world setting. In this case, students were asked to complete projects based on a real-world school library media center of their choice. There are three major project-based assignments in ECI 675 which are based on a functioning school library media program. These are the Facili- ties project in which students plan for the instructionally-based renovation of a school library media center, Grantwriting in which students develop a grant application to add materials to a school library collection, and a Bud- get project in which students prepare a written budget presentation for the school library program. The online cohort was graded on class participa- tion using Blackboard as a discussion medium. A final exam to test for con- tent knowledge rounded out the assessments used in the course. Design We utilized a posttest only, quasi-experimental design to ascertain whether online instructional delivery differed in its delivery compared to face-to-face delivery. Students in the online cohort (n = 1 9) were exposed to the content of ECI 675 through a distance education format. Specifically, the students could access the course whenever they wanted via a webpage managed through Blackboard software. This asynchronous delivery method enabled students to take the course while living outside the Hampton Roads area. This delivery method is also associated with "self-guided" learning because other than meeting project deadlines, the students did not have to be in class at any certain date and time. The two cohorts were given the same course requirements and written materials. Thus, the two groups received the same instructions on how to complete the projects as well as assigned the same readings and provided the same powerpoint materials. The instructor for both cohorts was the same - an experienced instructor in the field of library media and one with extensive experience in both online and face-to-face formats. The two classes differed in a few ways. The face-to-face cohort received in person
A Comparison of Online and Face-to-Face Cohorts 31 1 lectures while the online cohort received all their information through pas- sive media. The online cohort was asked to participate in graded discussion boards to foster community whereas the face-to-face section participated in non-graded discussion during class time. The dependent variables measuring student performance were collected at the end of the semester. Specifically, the instructor provided project grades, final exam, and final point totals for both cohorts. We collected de- mographic information from application forms in student files. Measures The evaluation of student performance, the dependent variables, in the on- line and face-to-face cohorts was based on the projects, final exam and final aggregate points in the ECI 675 course. The course projects highlighted Fa- cilities, Grantwriting, and Budget in the library media field. Each project had several components and we compared performance on the individual components as well as the projects as a whole. Each project totaled 40 points. A description of the projects and the individual components are pre- sented below. Facilities Assignment overview This assignment is the first major project in the school library media pro- gram. The project requires students to analyze an existing library media center and develop a plan for the renovation using limited funds. â¢ Facilities Part 1: Mission: Students are required to state the mission of the school library media program in the school "to ensure that students and staff are effective users of ideas and information" and discuss their personal vision of the library media center space. â¢ Facilities Part 2: Evaluation: Students are required to evaluate the library space as it relates to the four types of access "physical, intellectual, economic, and emotional" and the major areas of the library, including large group instructional area, leisure reading, workroom, and other spaces. â¢ Facilities Part 3: Revision: Based on the evaluation in Part 2, students must develop a plan for resolution of problem areas. Reasons for the changes must be instructionally sound and relate back to the mission (Part 1). The allocated budget for changes is $3000. â¢ Facilities Part 4: Overall: The plan includes a required 2-minute narrated video of the library and before - and after - floor plans. Plan must be well-written as a professional memo to the principal. Grantwriting School librarians frequently assume the role of finding alternative sources of funding for the school library program. Developing a fundable grant pro- posal is an important part of program administration. In this assignment, students use the grant criteria and application for the Laura Bush Founda-
312 Journal of Education for Library and Information Science tion for America's Libraries, which provides books for America's neediest school libraries. â¢ Grantwriting Part 1: Technical: Students are assessed on the degree to which they follow the grant specifications, including allowable word count, intended use of the grant, and quality of writing. â¢ Grantwriting Part 2: Content: Use of funds must be related to improvement of instruction and justified by using research into adequate yearly progress (AYP) and strength of the library collection. The school description must also be related to the proposed use of funds. â¢ Grantwriting Part 3: Analysis: Sometimes in grant writing the individual questions seem to be very similar. Students are assessed in this section on the story that they present to the grant funders through their answers to the individual questions. Each answer must be unique and contain information crucial to a full understanding of the grant. Budget Students must prepare a written budget presentation for the operation of the library media program in the coming fiscal year. They must have a sound budget philosophy based on the mission, provide research into the develop- ment of the budget requests, and provide an instructional justification for each budget category. â¢ Budget Part 1: Research: Students must provide a budget philosophy statement based on the mission and their beliefs about children and libraries. Budget figures must be based on comparative data at the local or national level. Research process must be included. â¢ Budget Part 2: Justification: Students must justify each budget category based on the improvement of teacher instruction and student learning. An exact dollar figure must be provided for each category. â¢ Budget Part 3: Scenario: The scenario places the reader at least 5 years into the future and paints the picture of the funded library program available to students and teachers at that time. Scenario must be no more than one page. â¢ Budget Part 4: Acquisitions: Part 4 requires the submission of five purchase requisitions, each completed in the proper format, with complete vendor address, item number and description, and tax and/or shipping if appropriate. We also compared student performance on the final exam. The nine-question, comprehensive exam was a content-based exam consisting mostly of essay questions. Students could earn up to 40 points on the final exam. Finally, we compared how the two groups fared in terms of final point av- erages. We converted the points into percentages (points earned/points pos- sible x 100) so that the two groups would be strictly comparable. The final
A Comparison of Online and Face-to-Face Cohorts 313 points total includes points accrued for the projects, discussion, a poster project, and attendance at a one-day regional conference of the state school library professional association. The online cohort final points total was 50 points higher due to the fact that they were graded on discussion so the per- centage of final points gives an aggregate, project and content performance combined, measure of student performance. We collected demographic information about the students that is typi- cally associated with student performance. The independent variables in- cluded undergraduate GPA, highest degree attained, gender, race/ethnicity, and years of teaching experience. These variables were self-reported by candidates on application materials for the SLMS graduate program. Analytic Approach Our analytic approach was designed to present a straightforward compari- son of the student performance in the DE and F2F cohorts. We first compare the means of achievement indicators for the two groups using independent samples t-tests. The comparison of means gives us a rough indication of the performance of the two groups in an easily interpretable format. However, we expected that variables other than the instruction delivery method (DE versus F2F) have an effect on student achievement. Research indicates that previous academic performance, race, gender, and experience all may have independent effects on student performance. Therefore, we included these variables as well as the instructional delivery method in ordinary least squares regression models (OLS). The inclusion of these variables lets us determine if the instructional delivery method has a statistically significant effect on student performance independent of other factors that may affect student performance. Results The purpose of this study is to determine if there are differences in the per- formance of students in a library media specialist graduate program given the same exact course content yet delivered that content in two different manners: online and face-to-face delivery. We developed two research questions to guide our study: How did online and face-to-face cohort per- formance vary on ( 1 ) projects and (2) content? We hypothesized that the two cohorts - distributed and face-to-face - would perform similarly on the ECI 675 course requirements. The results from our statistical analyses indicate mixed support for our hypotheses. The online cohort earned slightly fewer points on the project based activities than did the face-to-face cohort. However, the two cohorts performed equally on the content based activities. A detailed presentation of the results below are or- ganized by the two research questions. Research Question 1 : How does the online cohprt perform compared to the face-to-face cohort on project based activities? The students were asked to complete three projects each of which had sev-
314 Journal of Education for Library and Information Science eral sub-components. We compared the performance of the two cohorts on each of the components and the projects as a whole to determine if the course delivery method influenced student achievement. A simple compar- ison of means indicates that the two cohorts scored highly on all the pro- jects earning, on average, a large percentage of the possible points. The two cohorts differed on some of the projects and their components. The first project students were asked to complete concerned Facilities and required students to analyze an existing library media center and develop a plan for the renovation using limited funds. When we compared means, the distance education and face-to-face cohorts scored similarly on the Mis- sion, Revision, and Overall components of the project. The face-to-face co- hort scored significantly higher on the Evaluation component of the Facilities project with a mean score of 9.4 (out of a possible 10 points) com- pared to 8.2 points for the online cohort (See Table 4). The OLS regression analysis of the Facilities project indicates that the face-to-face cohort did significantly better on the Evaluation, Revision and Total project portions (See Table 5). Students in the online cohort were likely to earn fewer points than the face-to-face cohort on Facilities Evaluation which required stu- dents to evaluate the library space as it relates to the four types of access "physical, intellectual, economic, and emotional" and the major areas of the library, including large group instructional area, leisure reading, work- room, and other spaces. The distributed group were likely to have scored significantly lower on the Revision portion of the project which asked stu- dents to develop a plan for resolution of problem areas in their Evaluation component. The online cohort was also likely to have scored approxi- mately 2.5 points fewer than the face-to-face cohort (out of a possible 40 points) on the Total project all other characteristics being equal. Notably, minority candidates, regardless of the instructional method, were likely to have scored significantly lower than white candidates on the Revision, Overall and Total Facilities project. In Table 6, we compare the mean scores for the Grantwriting Project in which students used the grant criteria and application for the Laura Bush Foundation for America's Libraries. The face-to-face cohort had signifi- Online Face-to-Face Facilities Points Possible Mean Mean Sig Mission 5 4.1 4.6 Evaluation 10 8.2 9.4 Revision 15 14.1 14.3 Overall 10 9.4 9.2 Total 40 35.7 37.6 N 19 14 Table 4 Comparison of means on Facilities Project and Components.
A Comparison of Online and Face-to-Face Cohorts 3 1 5 .? * * : 5! * * * "5 ^ooTooo o 2 S 0 Â» Â§~5Â£Â£8^- ooo7ooo o .2> + ; ; Â§ is o > 2 OÃ­ Lr)0)r-(^^00) ^ OOOr-^OLO Â° ^ q OOOr-^OLO I I I I Â° I r- ^ q ^ O) . JÂ» ^ â¢ o .? o c " O a ^ to 1 c^Â£::Â£cnjcoo ud^ lOOOdd^r d#a q -~-^^-^ Ã² fÃ glio, :" Â° S " * I -s ^~ Â£ a, O) Ã2 .^ a) ^ S Â° â¢- C0^Q(O<oto v o1 'o (Ã u. CO Ã to Q) ts (D (Ã O o Q. O) O 0 io o â¢e (ti "Â° co o CD O (0 fi e o â¢o 'o o uo a> Ã5) o co O
316 Journal of Education for Library and Information Science Online Pace-to-Pace Grantwriting Points Possible Mean Mean Sig Technical T5 9~6 9*5 Content 15 12.7 13.9 Analysis 15 14.1 14.9 Total 40 36.4 38.3 N 19 14 Table 6 Comparison of means on Grantwriting Project and Components. cantly higher mean scores on the Content (13.9 versus 12.7 points) and Analysis (14.9 versus 14.1 points) components which contributed to a sig- nificant difference in the Total Project scores (36.4 versus 38.3 points). However, the two cohorts were likely to score similarly on the Technical component. These results carried through the regression analyses (See Ta- ble 7). Independent of other factors that may have affected project scores, the online cohort was likely to score fewer points on the Content and Analy- sis components of the Grantwriting project but the same on the Technical portion. Thus, the online cohort was less successful in describing the use of grant funds as related to the improvement of instruction as well as presenting a "story" to grant funders. The Budget project requires students to prepare a written budget presen- tation for the operation of the library media program. The DE and F2F co- horts performed equally well on most of the project components. Students in the online cohort earned significantly fewer points on the Justification ^ Technical Content Analysis Total B Sig B Sig B Sig B Sig Online (F2F omit) 0014 ^423 *** -0.680 ~ -2.088 ~ Undergrad GPA -0.530 0.283 -0.210 -0.457 Masters (Bach omit) 0.000 -0.043 -0.342 -0.385 Minority (White omit) -0.795 + -0.866 0.340 -1.321 Female (Male omit) -0.233 0.736 -0.361 0.142 Age 0.012 0.032 -0.019 0.024 Constant 11.517 *** 12.318 *** 16.029 *** 39.864 *** N 32 32 32 32 f? 0.160 0.436 0.492 0.356 Table 7 OLS Regression of Student Performance on Student Demographic Characteristics: Grantwriting Project.
A Comparison of Online and Face-to-Face Cohorts 317 Online Face-to-Face Budget Points Possible Mean Mean Sig Research T5 8"5 8~7 Justification 10 8.2 9.1 Scenario 10 8.3 9.1 Acquisitions 10 9.9 8.4 Total 40 34.9 35.3 N 19 14 Table 8 Comparison of means on Budget Project and Components. component of this project earning an average 8.2 points compared to the face-to-face average of 9.1 points (See Table 8). Interestingly, the distrib- uted cohort scored higher than the face-to-face cohort on the Acquisitions portion of the project (9.9 points compared to 8.4 points). When we ac- counted for other variables that could have affected student performance, we found that the two cohorts only performed differently on only one pro- ject component (See Table 9). The online cohort scored significantly fewer points than the face-to-face cohort on the Justification portion (B = - 1 .088, p < 0.001). The two cohorts performed equally as well on the Research, Scenario, Acquisitions and Total project components. Again, minority sta- tus predicted lower scores on most of the Budget project components. Research Question 2: How does the online cohort perform compared to the face-to-face cohort on content based activities? We were interested in determining if the two cohorts performed similarly on assessments of content knowledge in addition to determining if they could complete project based activities in the same manner. To assess con- tent knowledge achievement, we examined the results on the Final Exam and the percentage of total points earned. The Final Exam was a nine-ques- tion exam consisting mostly of essay and short answer questions that sur- veyed knowledge gained over the entire semester. We found that the two cohorts, DE and F2F, performed equally as well on the Final Exam with av- erage scores of 34.7 and 34. 1 respectively (See Table 1 0). Even when the ef- fect other variables was controlled, the two cohorts showed no statistically significant differences in their performance (See Table 1 1). We found similar results when we examined the cohorts' performances on the Total Points Earned. This measure takes into account all facets of the course - knowledge, project based work, and discussion. The face-to-face and distributed cohorts both scored equally as well in the course as a whole. The online cohort earned an average of 90.9% of the total points possible whereas the face-to-face cohort earned 92.3%. These totals were not statis- tically different (See Table 10). After controlling for other demographic
318 Journal of Education for Library and Information Science Â§ > â¢ i 1 - 2Sgs5Â§M g </> o ? flu S^P^^pcoCNJ^ .2> + : GO ~ .2 O) <Q o c 3 0) O O) -. n r- n n o Â°7o77oÂ£ d s TOOOoOoi o O) . r 770700^ Ã² s ill Eg o Â« o ll^ (a iÃ¼ >- ' Â£, 4-. Â© O)ÃÃQ) Â§ C Q) B O "3 ^ Ã­ O) Â«i o Â« s o 2 O a 2 E o Â«e o I 4-Â» O T3 o 'Â«TÃ­ (/> 1 (A O
A Comparison of Online and Face-to-Face Cohorts 3 1 9 Online Face-to-Face Budget Points Possible Mean Mean Sig Exam 40 34~7 34~1 Percent of Total Points 100 90.9 92.3 N 19 14 Table 10 Comparison of means on Final Exam and Percent of Total Possible Points. variables, the two cohorts were likely to have performed similarly in terms of the percentage of points earned in the class (See Table 1 1). Discussion ECI 675 is a project-based course covering the program administration role of the school library media specialist. Final grades are determined by course projects which are based on a functioning school library media pro- gram of the student's choice, a final exam, and by class participation con- cerning specific discussion questions. This study compares points earned in the projects and on the final exam by students in face-to-face and online cohorts. Our findings indicated no significant difference between the final exam scores of the face-to-face and online cohorts, nor in the final grades. Thus, we assert that the content knowledge of the online cohort and the F2F class were the same. On individual projects, however, there were significant differences and the online cohort invariably scored fewer points than the face-to-face co- r iridi uidueÂ» Final Exam Final Percent B Sig B Sig Online (F2F omit) 0.344 -1.989 UndergradGPA 2.444 -0.717 Masters (Bach omit) -1 .792 -1 .232 Minority (White omit) -2.679 -5.899 + Female (Male omit) -1.663 -1.462 Age -0.026 -0.133 Constant 28.841 *** 96.489 N 32 32 R2 0.341 0.181 Table 11 OLS Regression of Student Performance on Student Demographic Characteristics: Final Exam and Percent of Total Points Possible.
320 Journal of Education for Library and Information Science hort. Tallman and Fitzgerald26 noted that a face-to-face class received more tips on assignment completion than an online class. "One of the most diffi- cult issues with online teaching has been to make the clarity of assignments such that students understand what they need to do. Face-to-face classes provide instructor access for explaining, modeling, and rewording assign- ments for people who need the support. Online, it had to come through the virtual office hour chats or via individual e-mail and discussion board com- munication and example assignments from previous classes. This meant students had to take more responsibility in letting the instructor know of their problems, not easy for many students." This was partially true for this study. The parts of the rubrics that graded technical or logistical aspects of the assignments, i.e. if they were com- pleted correctly, found no significant difference. Differences occurred in the areas where students were expected to reflect, to draw conclusions, or to relate their work in the assignment to the instructional program of the school. In the Facilities project, the evaluation of the current facility must be related to the instructional activities that occurred in the library. In the Budget, the instructional justifications for each budget item were to do the same. In the Grantwriting, the content of the grant must reflect the impact of the grant on the school and community. It is probable that the F2F class received more assistance in developing an approach to the assignments that helped them move beyond descriptive writing to analysis and reflection. Limitations The current gold standard in educational research is the use of true experi- ments to determine differences in instructional approaches. However, there are relatively few studies that can employ this research design due to the real world problems with randomly selecting students to participate in courses and randomly assigning them to different treatments. For this study, we would have had to randomly select potential SLMS candidates from three geographical areas in Virginia and then randomly assign them to online and face-to-face programs. This is just not feasible. Therefore, we employed the next best research design in which we allowed candidates to self select themselves into the program and treatment groups, yet we con- trolled for other factors that may have affected their performance. We in- cluded powerful predictors including how they performed in their undergraduate studies, race/ethnicity, and gender. Although we included powerful predictors, the R2 statistic in our regres- sion analyses indicates that we have not fully specified our models. This means that there may be other independent factors that affected student per- formance that we did not measure in our models. However, the R2 statistics are certainly large enough for us to feel confident that we have accurate and robust predictors of student performance and have successfully determined if there are differences between online and face-to-face delivery. One threat to the internal validity of the research study concerns the pos- sible influence of the instructor who was aware of the research study and is
A Comparison of Online and Face-to-Face Cohorts 321 one of the authors of this paper. Although the instructor attempted to keep the instruction strictly parallel in the two classes, it is possible that subcon- sciously she favored one or the other sections. We employed some systems to minimize such bias. In interviews with the instructor after the course was completed, another author attempted to locate bias and was not able to find evidence that one section was favored over another. The assessments were graded with scoring rubrics. We asked a professional in the field with de- cades of teaching experience to ensure that the rubrics were ( 1 ) well written and organized, (2) detailed in terms of content so that all necessary content was sampled, (3) detailed in terms of achievement descriptions (i.e., what constituted excellent compared to very good work), and (4) detailed in terms of point distributions. In email correspondence, the reviewer indi- cated that the rubrics would allow reasonably objective assessment of stu- dents and that "The rubrics appear to be specific enough to allow a fair comparison of the results of their use." In future studies, we hope to estab- lish systems of overlapping grading to establish inter-rater reliability. Be- cause this was an exploratory study, we did not have these processes in place. Likewise, the students in both sections were aware that their perfor- mance would be recorded as part of a research study. This could have re- sulted in some form of Hawthorne effect in one or both of the sections. Even though the study has limitations in terms of design, it is certainly a step forward in the illumination of the delivery of SLMS training programs. Indeed, our preliminary findings suggest that further research is necessary. For example, there may be ways to strengthen the delivery of project-based instruction through distance education by increasing communication or re- vamping written descriptions of projects. These interventions need to be assessed. We plan on extending our research to other online courses in the program and strengthening the research design with reliability checks. And, although our findings suggest that project-based learning is more dif- ficult to deliver through DE versus F2F, our findings are preliminary and should not be overgeneralized. Recommendations In this study, we found no significant differences in student content knowl- edge between the two delivery methods. We did find, however, that the two cohorts performed differently on certain project components. Thus, our recommended changes to the course concern the interaction between stu- dents and the instructor. These include offering greater assistance in inter- preting the rubrics for each assignment and more interaction with students while they are completing the assignment. We suggest using the Announce- ments page on the online course to call student attention to parts of the ru- brics and instructor postings reminding students of the types of reflection needed for a target-level project. Most significantly, we suggest that online instruction may be a viable mechanism for delivering SLMS training to underserved areas of the
322 Journal of Education for Library and Information Science United States. With certain modifications to the project delivery, we expect that the two cohorts would perform equally as well as one another. Cer- tainly, the comparable gains in content knowledge of the two cohorts in this class is a promising indicator that online instructional delivery for SLMS training should be explored further. Acknowledgments The authors would like to thank the anonymous reviewers for their insight- ful comments. This project was made possible by a grant from the U.S. In- stitute of Museum and Library Services. References 1 . Dan Barron, "Distance Education in Library and Information Science: A Long Road Trav- eled," Journal of Education of Library and Information Science 43, no. 1 (2002): 3-5. 2. Ellen B. Mandinach, The Development or Ettective Evaluation Methods tor b-Learning: A Concept Paper and Action Plan," Teachers College Record 1 07, no. 8 (2005): 1814-1835. 3. Barbara A. Frey, et al., "Student Satisfaction with the Online MLIS Program at the Univer- sity of Pittsburgh," Journal of Education for Library and Information Science 45, no. 2 (2004): 82-97. 4. Hak Joon Kim and James Michael Kusack, "Distance Education and the New MLS: The Employers* Perspective," Journal of Education for Library and Information Science 46, no. 1 (2005): 36-52. 5 . Dan Barron, ed. , Creating Opportunities for Distant Learners: Models from Library and In - formation Science (Littleton, CO: Libraries Unliminted, 2002); Carol Simpson and Yunfei Du, "Effects of Learning Styles and Class Participation on Students' Enjoyment Level in Distributed Learning Environments," Journal of Education for Library and Information Science 45, no. 2 (2004): 123-135; and Frey, "Student Satisfaction with the Online MLIS Program at the University of Pittsburgh." 6. Laura B. Raphael, "Far and Away: The Pros and Cons of a 'Long-Distance' MIS," Ameri- can Libraries 33, no. 9 (2002): 20-52; Joanne Bunn, "Student Persistence in a LIS Distance Education Program," Australian Academic and Research Libraries 35, no. 3 (2004): 253-269; Julie Tallman and Mary Ann Fitzgerald, "Blending Online and Classroom Learn- ing Environments," Knowledge Quest 34, no. 1 (2005): 25-28; Davison M. Mupinga, Rob- ert T. Nora, and Dorothy Carole Yaw, "The Learning Styles, Expectations, and Needs of Online Students," College Teaching 54, no. 1 (2006): 1 85-1 89; and Frey, "Student Satisfac- tion with the Online MLIS Program at the University of Pittsburgh ." 7. Kim, "Distance Education and the New MLS." 8. Reba Palloff and Keith Pratt, Building Learning Communities in Cyberspace: Effective Strategies for the Online Classroom (San Francisco, CA: Jossey-Bass, 1999); Robert Woods and Samuel Ebersole, "Becoming a 'Communal Architect' in the Online Class- room - Integrating Cognitive and Affective Learning for Maximum Effect in Web-Based Learning," Online Journal of Distance Learning Administration 6, no. 1 (2003), http://www.westga.edu/%7Edistance/ojdla/spring61/woods61.htm (accessed May 2, 2006); and Scott Nicholson, "A Framework for Technology Selection in a Web-based Dis- tance Education Environment: Supporting Community-Building through Richer Interac- tion Opportunities," Journal of Education for Library and Information Science 46, no. 3 (2005): 217-233. 9. Alfred Rovai, "Building Sense of Community at a Distance," International Review of Re- search in Open and Distance Learning 3, no. 1 (2002), http://www.irrodl.org/in-
A Comparison of Online and Face-to-Face Cohorts 323 dex.php/irrodl/article/view/79/l52 (accessed May 2, 2006); Alfred Rovai and Robert Lucking, "Sense of Community in a Higher Education Television-based Distance Educa- tion Program," Educational Technology Research and Development 5 1 , no. 2 (2003): 5-16; and Qing Li and Melina Akins, "Sixteen Myths about Online Teaching and Learning in Higher Education: Don't Believe Everything You Hear," TechTrends 49, no. 4 (2005): 51-60. 10. Nicholson, "A Framework for Technology Selection." 1 1 . Mary Bold, "Development and Evaluation of a Distance Learning Master's Degree in Fam- ily Studies," Online Journal of Distance Learning Administration 8, no. 3 (2005), Available at: http://www.westga.edu/%7Edistance/ojdla/fall83/bold.83.htm (accessed April 26, 2006); and Kim, "Distance Education and the New MLS." 12. Bold, "Development and Evaluation of a Distance Learning Master's Degree in Family Studies." 1 3. Mary K. Tallent-Runnels, et al., "Teaching Courses Online: A Review of the Research," Re- view of Educational Research 76, no. 1 (2006): 93-135. 14. Barron, "Distance Education in Library and Information Science." 1 5. Mandinach, "The Development of Effective Evaluation Methods for E-Learning." 16. Ibid., 1814. 17. Li, "Sixteen Myths about Online Teaching and Learning in Higher Education." 18. Jennifer Patterson Lorenzetti, "Beyond Multiple Choice: Assessment for Online Learn- ing" Distance Education Report 9, no. 18 (2005): 1-2. 1 9. Johanna TuÃ±?n, "The Impact of Accreditation and Distance Education on Information Lit- eracy," Florida Libraries 46, no. 2 (2003): 1 1 - 1 4; and Bold, "Development and Evaluation of a Distance Learning Master's Degree in Family Studies." 20. Jace Hargis, "Collaboration, Community, and Project-Based Learning - Does it Still Work Online?" International Journal of Instructional Media 32, no. 2 (2005): 157. 21 . Tallman, "Blending Online and Classroom Learning Environments." 22. Ibid., 27. 23. Virginia Department of Education, Division of Teacher Education and Licensure. Report on Supply and Demand of Instructional Personnel in Virginia. http://www.pen.k 12.va.us/ VDOE/newvdoe/teached.html (accessed December 1 5, 2004). 24. Virginia Educational Media Association. The Status of School Library Media Specialists in Virginia, 2000. http://www.vema.gen.va.us/survey.html (accessed December 15, 2004). 25. Virginia Department of Education. 2005-2006 Fall Membership- Division Summaries by Ethnicity, 2005. http://www.pen.kl 2. va.us/VDOE/dbpubs/FallJvtembership/2005/ FallMemDivRace2005.xls (accessed May 2, 2006). 26. Virginia is for Business. Community Profiles, 2005. http://virginiascan.yesvirginia.org/ Data_Center/Community_Profiles/Default.aspx (accessed May 2, 2006). 27. Tallman, "Blending Online and Classroom Learning Environments."