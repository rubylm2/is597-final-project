Deans Rank Indicators of Effectiveness for Schools of Library and Information Studies Rebecca Watson-Boone and Dartene Weingand This article identifies indicators of effectiveness that deans of schools with American Library Association (ALA) accredited programs believe are "essential," "important," or "not important" to know about a school of library and information studies (LJS) in order to evaluate it. A previous article by the same authors focused on views that members of four constituent groups of LIS schools hold about the same indicators.1 Comparing deans with the constituent groups, there is 77 percent agreement between deans and members of ALA's Committee on Accreditation (COA) over which indica- tors of effectiveness belong in each of the three designated categories. There is less agreement between deans and senior academic administrators (70 percent), alumni (57 percent), and employers (44 percent). Overall, deans focus heavily on administra- tive, faculty, and resource issues. In 1992, the authors used the ALISE Re- search Award to support a study of indi- cators and dimensions of effectiveness of schools with ALA-accredited programs. The objectives of the study were: 1. To identify indicators and dimen- sions of effectiveness that are de- scriptive of ALA-accredited LIS programs and that are believed by the schools* constituents to be useful in evaluating schools' effectiveness; 2. To ascertain the similarities and differences in the concepts and in- dicators underlying LIS school evaluations across constituencies; and 3 . To see if the results suggest avenues for strengthening current schools, as well as for viewing the future of schools of library and information studies (SLIS). For the purpose of that study, the four constituent groups were identified as members of COA, senior academic ad- ministrators, alumni/ae (hereafter "a- lums"), and employers of alums. Specifically, COA participants were members and officers from 1986-1991. Respondents from the other three con- stituencies were related to participating LIS schools. Senior academic adminis- trators were represented by each insti- tution's president, chief academic officer, graduate school head, chief fi- nancial officer, and the officer to whom the head of the SLIS reported. Employ- 30 Volume 37, Number 1
Deans Rank Indicators 3 1 About the Authors Rebecca Watson-Boone is President, Center for the Study of Information Professionals, Inc., and Darlene Weingand is Professor, University of Wisconsin-Madison School of Library and Information Studies. This article continues the presentation of research conducted under the 1992 ALISE Research Award. Manuscript received July 1994; accepted May 1995. ers were selected from within a 200- mile radius of participating schools. Al- ums of the schools were randomly selected from the schools' classes of 1980, 1985, and 1990. The researchers assumed that deans/directors of SLIS (hereafter, "deans") also have a vested interest in the effectiveness of their own school and a secondary interest in other LIS schools. Including deans in the study offered an opportunity as well to com- pare their views with those of the four constituent groups. Methodology A complete description of the method- ology is given in "Profiles of Constitu- ent Groups."2 To summarize, the "SLIS Effectiveness Study" adopted the method and structure used in the Childers and Van House "Public Library Effectiveness Study."3 In 1988-89, Childers and Van House conducted a national survey of public libraries' con- stituent groups. The study was notable because it asked respondents directly about the usefulness of various criteria (or indicators) and allowed for compari- son of several key constituent groups. As Childers and Van House noted, the inclusion of constituents "provided perspectives on the public library that are new and important for the library's relationship with its environment."4 To identify indicators that might have value to program deans, an exten- sive review was conducted of the 1982- 1991 LIS school and program literature. Sources included ERIC, LISA, accredi- tation standards, research reports, items from bibliographies, and library educa- tion texts. Six hundred words and phrases were found that described pro- grams, schools, and LIS education. These terms were collapsed into pro- gressively more general statements by employing the constant comparison method of building sets by grouping similar terms together.5 The final docu- ment consisted of seventy indicator statements formatted into a four-page questionnaire and arranged so as to avoid clustering related indicators. The question that served to elicit participant response to the indicators also was adapted from the Childers and Van House study: "In describing the effec- tiveness of a school of library & informa- tion studies to a person in a position comparable to yours, how important would it be for you to know each of the following about that school?" (empha- sis in original). Respondents were asked to rate each indicator in terms of its informative value for describing the ef- fectiveness of a school's LIS program. A five-point, three-category Likert scale was provided, ranging from one ("not important to know") to five ("es- sential to know"); a "no opinion" option was also given and was scored as zero. Winter 1996
32 Journal of Education for Library and Information Science Participants were asked to rate each in- dicator/statement by circling the num- ber that "reflects your opinion." Additional comments were invited. Participants were instructed that they were not rating a particular LIS school. The deans of participating schools re- ceived the same questionnaire form and instructions as those sent to partici- pants from the four constituent groups. Eligible Programs and Questionnaire Response The fifty-nine ALA-accredited pro- grams6 comprised the population. Pro- grams were excluded if they were experiencing some form of change, such as closure, restructuring, or extraordi- nary review, or were without a perma- nent dean. A few schools declined to participate; others did not respond in time. Thirty-five schools participated in the overall SLIS effectiveness study; deans from twenty-nine of those schools also participated (83 percent re- sponse). The deans' responses form the substance of this article. Analysis The Likert scale for each indicator had three clusters: ■ 1 and 2 equated with the phrase "not important to know," ■ 3 with "important to know," and ■ 4 and 5 with "essential to know." Although the data is ordinal, it is common for Likert scale means to be calculated so responses can be ranked. Means for deans' responses ranged from a low of 2.086 to a high of 4.657 on the 1-5 scale. The SPSS program that calcu- lated means also ran one-way ANOVAs, including Scheffe tests of statistical dif- ference. No statistical inference is in- tended in the discussion that follows. However, the means are used to denote the importance deans give to each of the seventy indicators and to the particular placement of indicators within each of the three categories. The authors are sat- isfied that the means reflect the prefer- ence deans have for each indicator as a measure of the effectiveness of schools of library and information studies. Findings The seventy indicator statements clus- ter into the following eight inductively derived groups: administration, al- ums/employment, continuing educa- tion, curriculum, faculty, recruitment, resources, and students. The authors used the constant comparative method of grounded theory to derive the groups. Comparison between the deans' ranking and those of the four constitu- ent groups is made throughout the text. The wording of each indicator (appen- dix) is incorporated into the text where appropriate, rather than being continu- ously offset by quotation marks. "Essential to Know." Deans place twenty-two indicators of effectiveness in this category. They focus on admin- istrative and faculty issues as being most crucial to know about schools of library and information studies. They place secondary emphasis on curricu- lar, alum, and employment matters. Table 1 shows those indicators comprising the first septile ("top ten"). The indicators are listed in descending order of mean value from 4.657 to 4.200. Asterisks identify indicators that all four constituent groups (e.g., COA, ad- ministrators, alums, employers) also rank among their "top ten."7 Deans clearly concern themselves Volume 37, Number 1
Deans Rank Indicators 33 Table 1 Dean's Essential to Know "Top 10" Indicators * Accreditation status - Ability of dean/director to represent the school to institutional administrators - Faculty involvement In research (e.g., quality, areas» productivity) - Reputation of the faculty (e.g., on campus, In other LIS schools, within the profession) * Reputation of the school within the institution, within the profession - Admissions standards (e.g., GPA, undergraduate institution) * Employers' view of the school's graduates * Faculty awareness of new developments in the field - Characteristics of graduates (e.g., involvement in professional assns., nationally recognized as leaders) - Visibility/involvement of the dean/director on campus, within the profession * = Ranked among the top 10 Indicators by all five groups with overarching indicators - those conveying an overall characterization of a school. Although only two of the seventy indicators specifically name the dean as the basis for the statement, it is not surprising that deans would place indicators that directly relate to themselves among their "top ten." The highest ranked of all seventy indicators is the accreditation status of a school - an administrative issue (ap- pendix). This is followed by the ability of the dean to represent the school to institutional administrators. The repu- tation of a school within its institution and profession, and the relative priori- ties a school gives to teaching, research, and service round out essential admin- istrative concerns. A fifth administra- tive indicator is also found in this cate- gory: the priority the school gives to teaching, research, and service. Deans and the four constituent groups agree that a school's accreditation status and its reputation within its institution and profession are administrative matters of "top ten" importance as indicators of effectiveness. COA, administrators, and alums agree with deans on the essential importance of knowing a school's teach- ing, research, and service priorities; em- ployers consider this indicator highly important to know, but not essential. Seven (46 percent) of the indicators relating to faculty are spread through- out the essential to know category. In- volvement in both research and teaching is found here. Deans rank the research indicator third highest of all seventy indicators of effectiveness. COA and administrators also support the "essential" placement of faculty in- volvement in research. Deans rank the teaching indicator next to last in this category with a mean value of 4.00, whereas COA and administrators give it a "top ten" ranking. Faculty awareness of new developments in the field is given "top ten" significance by all five groups (table 2). The reputation of the faculty is accorded "top ten" standing by all except alums, who place it lower in this category. Deans also value fac- ulty receptivity to change, which may be evidenced through the latter's aware- ness of new developments. And, the relationship between faculty and stu- dents is of major interest to deans. Deans have no constituent group sup- porters in their belief that the size of the school's faculty is an essential to know effectiveness indicator. Curricular issues are not found in the deans' "top ten," but four are lo- cated lower within this essential cate- Winterl996
34 Journal of Education for Library and Information Science Table 2 w Essential to Know" Indicators with Strongest Agreement between Deans and Constituent Groups Indicator Ranking Accreditation status Top 10 in all five groups Faculty awareness of new developments in the Top 10 in all five groups field Reputation of the school (within institution, Top 10 in all five groups within profession) Goals and objectives of the school Top 10 for Admin., and Empl. COA = Essential Alums = Essential Deans = high Important Reputation of the faculty (e.g., on campus, in COA, Admin.. Empl.. Deans = Top 10 other US schools, within profession) Alums = Essential Employers' view of the school's graduates Top 1 0 for all five groups Speed with which new technologies are COA, Alums, and Empi = Top 10 incorporated into the curriculum Admin. = high Important Deans = Essential Rigor of the curriculum Admin., Alums, Empl., Deans = Essential COA = high Important Direction the school provides to professional Constituent groups = Essential practice Deans = high Important Faculty involvement in teaching COA, Admin. = Top 10 Alums, Deans = Essential Empl. = high Important Priority given by the school to (1) teaching, (2) Admin. = Top 10 research, and (3) service COA, Alums , Deans = Essential Empl. = high Important Table ordered in descending values of the overall mean of the four constituent groups Top 10 = in first septile Essential = within this category, but not ranked as one of first ten indicators high Important = placed in the second category (Important to Know) with a mean between 3.50-3.99 gory: program offerings, program re- quirements, rigor of a curriculum, and the speed with which new technologies are incorporated into a curriculum. Al- ums and employers support deans on all four. Administrators agree that knowing a curriculum's rigor is essen- tial, and COA agrees with the need to know the speed of incorporation of new technologies. Deans and all four constituent groups agree on only one other indica- tor in this category: the need to know how employers view the school's gradu- Volume 37, Number 1
Deans Rank Indicators 35 ates. Deans go on to target the place- ment of graduates in terms of types of agencies and level of position. They are concerned about graduates' charac- teristics as seen through the latter's in- volvement in professional associations, national recognition accorded them as leaders, and their commitment to serv- ice. Part of deans' interest in graduates includes the extent to which the latter think beyond immediate job needs to larger issues such as community in- volvement. Finally, deans want to know about both admissions standards and the characteristics of current students in order to assess the effectiveness of a school of library and information stud- ies. There is a 73 percent agreement be- tween deans and COA participants on what indicators belong in this crucial first category; employers and deans agree the least (45 percent) on which indicators to place in this category. Ad- ministrators agree with 59 percent of the deans' indicators, and alums with 68 percent of the deans' choices. "Important to Know." Deans place forty-three (61 percent) of the seventy indicators in this category. To gain a clearer sense of the preference for some indicators over others, and for discus- sion purposes, the mean is divided into "high" (3.50-3.99) and "low" (3.00- 3.49). Deans place the remaining induc- tively derived administrative and faculty indicators in this category. This is also where they put all ten resource indicators. High "Important to Know." Of the forty-three indicators found in the en- tire category, deans rank 60 percent of them in this subcategory. This is where they put the twin issues of the direction a school provides to professional prac- tice and its responsiveness to the needs of the profession. On placement of the "direction" indicator, deans are alone; all four constituent groups consider it essential to know (table 2). On the issue of "responsiveness," administrators join deans in placing it here, whereas COA, alums, and employers give it a "top ten" essential ranking. Were this interval data, the mean differences be- tween administrators and both alums and employers on the "responsiveness" indicator would be statistically signifi- cant. Deans believe that knowing the goals and objectives of the school be- longs here, although all four constituent groups give the indicator an essential ranking. Administrators, alums, and employers do support deans' "high im- portance" placement of the indicator that associates a school's curriculum with its goals and objectives. Deans also express high value in knowing the rela- tionship between a school's mission and the mission of its institution. On faculty issues, deans want to know how faculty are involved in school and institutional governance. They believe it is highly important to know the diversity of faculty back- grounds (e.g., ethnicity, gender, area of specialization, degrees), the use made of adjunct faculty and guest lecturers, and the extent of interdisciplinarity in faculty teaching and research endeav- ors. They are concerned with faculty involvement in professional associa- tions, as well as what relationships ex- ist between faculty members and practitioners. Lastly, deans value know- ing how satisfied faculty are with their home school. Deans consider all ten resource in- dicators important to know; seven are ranked as "highly important." Issues touching on faculty include the filling of faculty vacancies and the current fac- ulty's receipt of external funding. In Winter 1996
36 Journal of Education for Library and Information Science terms of the school itself, deans seek to know the relationship between a school's budget and its academic pro- gram needs (instructional and support). They want information on the manage- ment of a school's currently available resources, as well as on its ability to engage in external fund-raising. Two student-related resource is- sues are particularly valued by deans: The ratio of faculty to students, and the availability of scholarship and fel- lowship monies. Another student is- sue of high importance is enrollment information: size, ethnicity, race, gen- der, and number of students by pro- gram. They also want applicant information: number, quality, diver- sity, acceptance-rejection rate, under- graduate majors and preparation. In terms of graduates, deans focus on the ability of graduates to handle change and to engage in problem solving and decision making. Lastly, they want to know if a school's curriculum has a competency or theory orientation, and whether a mixture of theory and practice is pro- vided in courses. The extent of interdis- ciplinarity with the master's program also is found in this subcategory. Low "Important to Know." Con- tinuing with curricular issues, the avail- ability of fieldwork, internships, practica, and courses on specific topics are of less importance to deans. The integratedness, or unity, of the curriculum is also ranked here. Student level of knowledge in one or more specializations is the lowest ranked curricular issue in this subcate- gory and merits inclusion among deans' "bottom ten" indicators. The competency of students in core courses also receives low support. Deans place the extent to which graduates are fully trained for their first professional job here. While COA gives this latter effectiveness indicator high importance, administrators rank it as essential, and alums and employers place it among their "top ten." In evaluating schools, deans give low marks to knowing about the assess- ment programs a school uses. They have little interest in enrollment trends and in knowing about recruitment activi- ties, including those for targeted special groups. Deans express only minor con- cern about alums' financial or political involvement with the school. And they are relatively unconcerned about the re- lationship between a school and the li- braries on its campus. There is some interest in knowing organizational loca- tion of a school (e.g., independent school, within a college). Among resource indicators, deans see only modest value in knowing the number and type of support personnel a school employs. Even less weight is given to knowing salary comparability of a dean and faculty to counterparts on campus and in other LIS schools. Infor- mation on a school's physical facilities is given "bottom ten" status. Finally, two faculty indicators have both low importance and a "bottom ten" ranking. Deans are only slightly inter- ested in faculty experience as practitio- ners - a ranking supported by COA and administrators. And they have little in- terest in knowing that faculty from other departments may sit on thesis committees within a school. Table 3 lists those important to know indicators where deans and all four constituent groups have greatest agreement. "Not Important to Know." This category contains five indicators. They form part of the deans' "bottom ten" (appendix). Three relate to curriculum. Deans do not determine the effective- ness of a school through knowing about duplication of course content within a Volume 37, Number 1
Deans Rank Indicators 37 Table 3 "Important to Know" Indicators with Strongest Agreement between Deans and Constituent Groups Indicators Ranking Relationship of curriculum to the school's goals COA = Essential and objectives rest = high Importance Satisfaction felt with the school by its faculty Empl. = low Importance rest = high Importance Involvement of the school's faculty in all five groups = high Importance professional associations Diversity of faculty backgrounds (e.g., ethnicity. Empl. = low Importance gender, area of specialization, degrees) rest = high Importance Management by the school of its currently Empl. = low Importance available resources rest = high Importance Recruitment information (e.g., programs and Deans = in Bottom 10 activities, targeted special groups) rest = low Importance Physical facilities of the school, including sq. COA, Alums. = low Importance footage, conditions, location, etc. Admin., Deans = in Bottom 10 Empl. = Not Important Table ordered in descending values of the overall mean of the four constituent groups Essential = mean between 4.00-5.00 high Importance = mean between 3.60-3.99 low Importance = mean between 3.00-3.49 Bottom 1 0 = in seventh septile Not Important to Know = mean below 3.00 school or with other academic units on its campus. Likewise, they are not in- terested in knowing the availability of small group activities. They give bot- tom rank to whether or not a program is available via distance education. Placement of this latter indicator is in- teresting in light of the occasional flurry of discussion over the JESSE list- serv about distance education. Deans from schools with highly visible and viable distance education programs may rank it higher. Lastly, both continuing education indicators are found here. The availabil- ity of continuing education units and whether or not a continuing education program is offered through a variety of formats (including telecommunications and distance learning) are simply not important for deans to know in deter- mining a school's effectiveness. Yet, in a world of rapid change and exploding information, continuing education still may emerge as a dynamic indicator in the next decade. By reaching into the low important to know subcategory, a set of "bottom ten" indicators is created. Table 4 shows those indicators where there is agree- ment between at least three of the five groups. Two indicators are supported by the deans and all four constituent groups. Winter! 996
38 Journal of Education for Library and Information Science Table ordered in descending values of the overpll mean of the four constituent groups Essential = mean between 4.00-5.00 high Importance = mean between 3.50-3.99 low Importance = mean between 3.00-3.49 Conclusion In their placement of effectiveness indi- cators within essential, important, and not important categories, deans agree most frequently with COA [77 percent), followed by administrators (70 per- cent), alums (57 percent), and employ- ers (44 percent). Deans clearly focus on indicators that are highly valued by the two constituent groups that have the greatest power over decisions regarding LIS programs: COA and administrators. As Daniel points out, "peer judgment is at the heart of voluntary accreditation" and agreement is strong between deans and the LIS faculty and library practi- tioners who primarily comprise COA membership.8 Deans and COA partici- pants give greatest value to indicators that describe the administration of a school, along with curricular and fac- ulty issues. Both downplay indicators relating to current students. With regard to institutional administrators, the 1990s have turned into a period of di- minished and constrained resources for universities, causing many administra- tors to reexamine educational missions and roles while riding in "permanent white water."9 Deans clearly must posi- tion their schools and programs so that library and information science is seen as essential to the institutional mission. They evidence awareness of this in their high ranking of reputational, research, and resource indicators similarly val- ued by their administrator constituents. The remaining two constituent groups are potentially more powerful than in the past. As universities increas- ingly are challenged to become more Volume 37, Number 1 Table 4 "Bottom 10" Indicators: Agreement between Three or More of the Five Groups Indicators Bottom 1 0 Location Outliers Faculty involvement in Admin., Alums, Empl. COA = high Important governance Deans = high Important Organizational location of the Admin.. Alums, Empl. COA = low Important school within its institution Deans = low Important School's ability to engage in COA, Alums, Empl. Admin. = high Important external fund-raising Deans = high Important External funding received by COA, Alums, Empl. Admin. = Essential faculty Deans = high Important Involvement of faculty from all five groups other departments in thesis committees within the school Availability of small group all five groups activities in the curriculun Number and type of support COA, Admin., Alums, and Deans = low Important personnel Empl.
Deans Rank Indicators 39 accountable to external constituents, a- lums and employers could become more demanding and important.10 Deans may find it necessary to strengthen their connections with these two groups. The differences between deans and these two groups on indica- tor placement are significant. Alums and employers stress indicators relating to curricular and graduate employment issues, while downplaying those espe- cially favored by administrators: re- search and resources. Alums and deans agree on only 40 percent of indicators to put in the "top ten" and on only 20 percent of those to place in the "bottom ten" positions. The situation with em- ployers is hardly better: a 50 percent agreement for the "top ten" and a 30 per- cent agreement with "bottom ten" place- ment of LIS indicators of effectiveness. Two indicators are of particular im- portance to alums and employers, and illustrate areas where deans may find it useful to focus some additional atten- tion. The first is the role of a school vis-à-vis the profession. All four con- stituent groups consider knowing the direction a school provides to profes- sional practice an essential indicator of effectiveness. However, alums and em- ployers rank a school's responsiveness to needs of the profession in their "top ten," while administrators consider this latter indicator highly important. The differences are subtle but important: Does a school lead or respond? To be truly effective, it must do both. How can it work with each constituent group so that all four groups perceive it as effec- tively leading and responding? A school might, for instance, combine these two findings with the fact that administrators are also significantly less interested than other constituents in whether a curriculum is theory- or competency-based. Using the three findings, a school might decide to use its curriculum to respond to alums and employers' needs while focusing fac- ulty research and publication into only those areas that allow it to claim the type of ground-breaking knowledge (and direction) respected by adminis- trators. Deans also have an opportunity to gain increased support from alums and employers through judicious handling of the following indicator: the extent to which graduates are fully trained for their first professional job. Alums and employers place it among their "top ten." Administrators see it as essential, COA as a matter of high importance, and deans as a matter of low impor- tance. The notion of "fully" training someone has a particular reality for COA and deans, who see the complexity inherent in this indicator of effective- ness. However, it is likely that the other three groups use it as an accountability measure. Schools that include this issue as a part of a regular assessment pro- gram may find some identifiable specif- ics that can profitably be addressed. Schools contemplating curricular revi- sion might use the indicator as part of determining what changes alums and major employers would welcome. This study has demonstrated that deans focus heavily on administrative, faculty, and resource issues. Their placement of indicators of effectiveness bring them into close accord with COA and institutional administrators. It is suggested that increased collaboration on issues that alums and major employ- ers value would serve deans well. References and Notes 1. Rebecca Watson-Boone and Darlene E. Weingand, "Profiles of Constituent Groups: Indicators of Effectiveness of Winter 1996
40 Journal of Education for Library and Information Science Schools of Library and Information Stud- ies , " Journal of Education for Library an d Information Science 36 (Spring 1995): 104-25. 2. Ibid. 3. Thomas Childers and Nancy A. Van House, The Public Library Effectiveness Study: Final Report (Washington, D.C.: U.S. Department of Education, 1989), 31. 4. Thomas Childers and Nancy A. Van House, "Dimensions of Public Library Ef- fectiveness." LJSR 11 Í19891: 275. 5. Barney G. Glaser and Anselm L. Strauss, The Discovery of Grounded Theory: Strategies for Qualitative Research (New York: Aldine de Gruyter, 1967); Anselm Strauss and Juliet Corbin, Ba- sics of Qualitative Research: Grounded Theory Procedures and Techniques (NewburyPark,Calif.:SagePublications, 19901. 6. September 1991 COA listine. 7. See "Profiles of Constituent Groups" to make other comparisons. 8. Evelyn H. Daniel, "Accreditation," Li- brary Journal 110 (Apr. 1985): 50. 9. Jack H. Schuster and others, Strategic Governance: How to Make Big Decisions Better, American Council on Education Series on Higher Education (Phoenix, Ariz.: Oryx, 1994). 10. For example, see Frank Newman's Choosing Quality: Reducing Conflict Be- tween the State and the University (Den- ver: The Education Commission of the States, 1987). Volume 37, Number 1
Deans Rank Indicators 4 1 Appendix A Rank Order and Mean Category of Indicators of Effectiveness: Deans and Each Constituent Group Deans' Ranking of Indicators COA ADM ALM EMP Essential to Know (4.00-5.00) ("Top 10" Indicators) 1 Accreditation status 4E 2E IE IE Ranked highest of all 70 indicators by deans. COA ranked it fourth highest Administrators second, Alums first and Employers first. This ranking means all five groups considered it essential to know in order to evaluate a school. E = Essential to Know H = High Important to Know L = Low Important to Know N = Not Important to Know 2 Ability of dean/dir. to represent school to instit. admin. 5E 1 2E 44H 40E 3 Faculty involvement in research (e.g., quality, areas . . .) 13E 5E 35H 35H 4 Reputation of the faculty (e.g., on campus, in profession) 3E 3E 13E 9E 5 Reputation of the school (e.g., in instit., in profession) 2E IE 4E 3E 6 Admissions standards (e.g., GPA, course prerequisites . . .) 29H 8E 16E 23H 7 Employers' view of the school's graduates 1 1 E 9E 9E 8E 8 Faculty awareness of new developments in the field IE 4E 2E 2E 9 Characteristics of graduates (e.g., profl. involvement . . .) 14E 18E 52L 27H 10 Visibility/involvement of dean/dir. (e.g., on campus, in profession) 12E 27H 47H 41 L 11 Priority school gives teaching, research, service 18E 7E 25E 24H 12 Extent grads think beyond immediate job to larger issues 16E 46H 32H 12E 13 Program offerings (e.g., 6th year, doctoral . . .) 30H 22H 8E 19E 14 Placement of graduates (e.g., agency type, position level) 49L 17E 17E 26H 1 5 Size of the school's faculty 36H 44H 38H 47L 16 Receptivity of faculty to change 10E 28H 21 E 22H 17 Relationship between faculty and students 19E 32H 23E 30H 18 Rigor of the curriculum 26H HE 19E 13E 19 Characteristics of students (e.g., intellectual . . .) 23E 39H 56L 38H 20 Speed that new technologies are incorporated into curr. 9E 33H 10E 6E 21 Faculty involve, in teaching (e.g., competency, areas . . .) 7E 10E 20E 31 H 22 Program requirements (e.g., language, core, length . . .) 32H 38H HE 18E Important to Know (3.00-3.99) "High" (3.50-3.99) 23 Direction school provides to professional practice 22E 15E 18E 14E continued on next page Winter 1996
42 Journal of Education for Library and Information Science Deans' Ranking of Indicators COA ADM ALM EMP 24 Relationship bet. school's budget and academic prog, needs 27H 13E 46H 46L 25 Relationships between school's mission and instit. mission 45H 21 E 61 L 59N 26 School's responsiveness to needs of the profession 8E 26H 7E 4E 27 Relationship of curriculum to school's goals and obj. 6E 23H 29H 28H 28 Ability of graduates to handle change 1 5E 25H 34H 1 OE 29 Ratio of faculty to students 54L 16E 27E 33H 30 Diversity of faculty backgrounds (e.g., gender, degrees . . .) 25H 30H 41 H 45L 31 Filling of faculty vacancies 34H 45H 53L 57L 32 Orientation of grads re problem solving/decision making 24E 48L 37H 21 E 33 Involvement of the school's fac. in professional assns. 28H 42H 39H 34H 34 Relationship between faculty and practitioners 20E 43H 28H 20E 35 Scholarship and fellowship availability 51 L 36H 26E 39L 36 Goals and objectives of the school 17E 6E 12E 5E 37 Faculty involvement in governance in school, on campus 33H 63L 63L 63N 38 Management by the school of its currently avail, resources 39H 24H 49H 52L 39 Satisfaction felt with the school by its faculty 37H 37H 31 H 43L 40 Mixture of theory and practice provided in courses 31 H 50L 14E 16E 41 Applicant information (e.g., number, diversity . . .) 40H 19E 54L 53L 42 Enrollment information (e.g., size, diversity . . .) 47H 34H 60L 56L 43 Orientation of the curr. (e.g.. competency or theory-based) 21 E 51 L 24E 25H 44 External funding received by the faculty 62L 20E 70N 65N 45 School's ability to engage in external fund-raising 63L 41 L 67N 64N 46 Extent of interdisciplinarity in fac. teaching/research 38H 52L 45H 49L 47 Extent of interdisciplinarity within Master's program 42H 53L 33H 42L 48 Use of adjunct faculty, guest lecturers 59L 57L 50H 50L -Low" (3.00-3.49) 49 Organizational "location" of school (e.g., independent, in college) 56L 64N 62L 61 N 50 Assessment programs used by the school 52L 31 H 40H 44L 51 Extent grads are fully trained for first profl. job 35H 14E 5E 7E 52 Number and type of support personnel 65L 65N 66N 70N 53 Relationship between the school and the instit. libraries 48H 35H 22E 29H 54 Availability of courses on specific topics 43H 66N 3E 1 1 E 55 Competency of students in core courses 61 L 40H 51 L 37H Volume 37, Number 1
Deans Rank Indicators 43 Deans' Ranking off Indicators COA ADM ALM EMP 56 Availability of fieldwork, internships, practica 44H 64L 6E 17E 57 Unity of the curriculum (integratedness) 41 H 47L 30H 36H 58 Enrollment trends over past 5 years 57L 29H 58L 60N 59 Alums' involvement with the school 46H 60L 69N 69N 60 Salary comparability of dean/dir. and fac. to counterparts 58L 58L 68N 68N ("Bottom 10" Indicators) 61 Physical facilities of school (e.g., footage, conditions) 60L 61 L 57L 58N 62 Faculty experience as practitioners 501 49L 15E 15E 63 Recruitment information (e.g., program . . .) 55L 56L 55L 48L 64 Student level of knowledge in one or more specializations 53L 55L 43H 32H 65 Involvement of fac. from other departments in thesis com. 66N 62L 65N 62N Not Important to Know (1 .00-2.99) 66 Duplication of course content (e.g., in school . . .) 67N 59L 59L 67N 67 CE program offered in variety of formats 68N 68N 48L 51 L 68 Availability of program via distance education 64L 69N 36H 54L 69 Availability of small group activities in the curriculum 69N 70N 64L 66N 70 Availability of Continuing Education Units (CEUs) 70N 67N 42H 55L Winter 1996